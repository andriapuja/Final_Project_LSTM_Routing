{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00e0e7b8-028c-4ae1-b6d7-9e2570d868ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp source destination  packet id           path  number of hops  \\\n",
      "0    2.00000      A           I          0  A > D > G > I               3   \n",
      "1    2.00000      B           H          0  B > D > G > H               3   \n",
      "2    2.00000      D           H          0      D > G > H               2   \n",
      "3    2.00417      H           D          0      H > G > D               2   \n",
      "4    2.00625      I           A          0  I > E > B > A               3   \n",
      "\n",
      "   source_encoded  destination_encoded  path_encoded  \n",
      "0               0                    8  [0, 3, 6, 8]  \n",
      "1               1                    7  [1, 3, 6, 7]  \n",
      "2               3                    7     [3, 6, 7]  \n",
      "3               7                    3     [7, 6, 3]  \n",
      "4               8                    0  [8, 4, 1, 0]  \n",
      "     timestamp source destination  packet id                   path  \\\n",
      "463    79.0000      B           H         19      B > E > I > G > H   \n",
      "464    79.0000      D           H         39  D > B > E > I > G > H   \n",
      "465    79.0083      H           B         19      H > G > I > E > B   \n",
      "466    79.0104      I           A         19  I > G > H > F > C > A   \n",
      "467    79.0104      H           D         19  H > G > I > E > B > D   \n",
      "\n",
      "     number of hops  source_encoded  destination_encoded        path_encoded  \n",
      "463               4               1                    7     [1, 4, 8, 6, 7]  \n",
      "464               5               3                    7  [3, 1, 4, 8, 6, 7]  \n",
      "465               4               7                    1     [7, 6, 8, 4, 1]  \n",
      "466               5               8                    0  [8, 6, 7, 5, 2, 0]  \n",
      "467               5               7                    3  [7, 6, 8, 4, 1, 3]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data directly from the same directory as the script\n",
    "data = pd.read_csv('dataset_backup.csv')\n",
    "\n",
    "# Define IP to Node label mapping based on your topology connections\n",
    "ip_to_node = {\n",
    "    '10.10.1.1': 'A', '10.10.3.1': 'A', '10.10.2.1': 'A',\n",
    "    '10.10.4.1': 'B', '10.10.5.1': 'B',\n",
    "    '10.10.6.1': 'C',\n",
    "    '10.10.7.1': 'D',\n",
    "    '10.10.8.1': 'E',\n",
    "    '10.10.9.1': 'F',\n",
    "    '10.10.10.1': 'G', '10.10.11.1': 'G',\n",
    "    '10.10.1.2': 'C', '10.10.3.2': 'B', '10.10.2.2': 'D',\n",
    "    '10.10.4.2': 'D', '10.10.5.2': 'E',\n",
    "    '10.10.6.2': 'F',\n",
    "    '10.10.7.2': 'G',\n",
    "    '10.10.8.2': 'I',\n",
    "    '10.10.9.2': 'H',\n",
    "    '10.10.10.2': 'H', '10.10.11.2': 'I'\n",
    "}\n",
    "\n",
    "# Strip off any network masks or additional subnet notation if present\n",
    "data['source'] = data['source'].str.split('/').str[0]\n",
    "data['destination'] = data['destination'].str.split('/').str[0]\n",
    "\n",
    "# Map IPs to node labels\n",
    "data['source'] = data['source'].map(ip_to_node)\n",
    "data['destination'] = data['destination'].map(ip_to_node)\n",
    "\n",
    "# Index to node label mapping for paths\n",
    "index_to_label = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I'}\n",
    "\n",
    "# Update paths to use node labels instead of indices\n",
    "def index_to_label_path(path):\n",
    "    return ' > '.join(index_to_label[int(node)] for node in path.split(' > '))\n",
    "\n",
    "data['path'] = data['path'].apply(index_to_label_path)\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the encoder on all unique node labels present\n",
    "label_encoder.fit(list(index_to_label.values()))\n",
    "\n",
    "# Encode source, destination, and paths\n",
    "data['source_encoded'] = label_encoder.transform(data['source'])\n",
    "data['destination_encoded'] = label_encoder.transform(data['destination'])\n",
    "\n",
    "# Encode paths\n",
    "def encode_path(path):\n",
    "    return label_encoder.transform(path.split(' > ')).tolist()\n",
    "\n",
    "data['path_encoded'] = data['path'].apply(encode_path)\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e0b62fb-c00d-4d29-8e89-7b3356c082aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 8s 192ms/step - loss: 2.1608 - accuracy: 0.3545 - val_loss: 2.1014 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 2.0197 - accuracy: 0.3411 - val_loss: 1.8677 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 1.7116 - accuracy: 0.3411 - val_loss: 1.6046 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1.5408 - accuracy: 0.3411 - val_loss: 1.5045 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1.4453 - accuracy: 0.3411 - val_loss: 1.3850 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 1.3252 - accuracy: 0.4114 - val_loss: 1.2129 - val_accuracy: 0.4800\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.1120 - accuracy: 0.5117 - val_loss: 0.9666 - val_accuracy: 0.6267\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.8589 - accuracy: 0.7157 - val_loss: 0.6859 - val_accuracy: 0.7467\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5844 - accuracy: 0.8428 - val_loss: 0.4553 - val_accuracy: 0.9200\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.3911 - accuracy: 0.9331 - val_loss: 0.3131 - val_accuracy: 0.9200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3626 - accuracy: 0.8723\n",
      "Test Accuracy: 0.8723404407501221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = max(data['path_encoded'].apply(len))\n",
    "X = pad_sequences(data['path_encoded'], maxlen=max_length, padding='post')\n",
    "y = data['destination_encoded']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(index_to_label), output_dim=50, input_length=max_length))\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dense(len(index_to_label), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "model.save('path_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32a3ded6-1e1f-424b-9d92-747cc663b4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 10s 184ms/step - loss: 2.1529 - accuracy: 0.3128 - val_loss: 2.0914 - val_accuracy: 0.2766\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9424 - accuracy: 0.3476 - val_loss: 1.8054 - val_accuracy: 0.2766\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6313 - accuracy: 0.3476 - val_loss: 1.5878 - val_accuracy: 0.2766\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.5111 - accuracy: 0.3476 - val_loss: 1.5287 - val_accuracy: 0.2766\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 1.4140 - accuracy: 0.3476 - val_loss: 1.3955 - val_accuracy: 0.2766\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 1.2143 - accuracy: 0.4198 - val_loss: 1.0919 - val_accuracy: 0.4043\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.9042 - accuracy: 0.6845 - val_loss: 0.7094 - val_accuracy: 0.8723\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5778 - accuracy: 0.8235 - val_loss: 0.3768 - val_accuracy: 0.9468\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.3384 - accuracy: 0.9786 - val_loss: 0.2234 - val_accuracy: 0.9787\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2399 - accuracy: 0.9278 - val_loss: 0.1609 - val_accuracy: 1.0000\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 9s 162ms/step - loss: 2.1467 - accuracy: 0.3342 - val_loss: 2.0722 - val_accuracy: 0.2872\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 1.9250 - accuracy: 0.3449 - val_loss: 1.7303 - val_accuracy: 0.2872\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 1.6199 - accuracy: 0.3449 - val_loss: 1.5312 - val_accuracy: 0.2872\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 1.4986 - accuracy: 0.4118 - val_loss: 1.4721 - val_accuracy: 0.2872\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.3777 - accuracy: 0.3529 - val_loss: 1.2944 - val_accuracy: 0.4043\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 1.1240 - accuracy: 0.5909 - val_loss: 0.9389 - val_accuracy: 0.6489\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.7525 - accuracy: 0.7754 - val_loss: 0.5801 - val_accuracy: 0.8085\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.4383 - accuracy: 0.8930 - val_loss: 0.3162 - val_accuracy: 0.9468\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2613 - accuracy: 0.9091 - val_loss: 0.2305 - val_accuracy: 0.9468\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.2196 - accuracy: 0.9091 - val_loss: 0.2104 - val_accuracy: 0.9468\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 9s 171ms/step - loss: 2.1486 - accuracy: 0.3102 - val_loss: 2.0697 - val_accuracy: 0.3085\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 1.9253 - accuracy: 0.3396 - val_loss: 1.7164 - val_accuracy: 0.3085\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.6117 - accuracy: 0.3396 - val_loss: 1.5489 - val_accuracy: 0.3085\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.4816 - accuracy: 0.3396 - val_loss: 1.4520 - val_accuracy: 0.3085\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.3121 - accuracy: 0.4198 - val_loss: 1.2321 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0024 - accuracy: 0.5936 - val_loss: 0.8828 - val_accuracy: 0.6915\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6280 - accuracy: 0.8610 - val_loss: 0.5141 - val_accuracy: 0.8404\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3687 - accuracy: 0.8957 - val_loss: 0.3341 - val_accuracy: 0.8511\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.2511 - accuracy: 0.9037 - val_loss: 0.2556 - val_accuracy: 0.8617\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.2171 - accuracy: 0.9118 - val_loss: 0.2236 - val_accuracy: 0.9255\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 8s 175ms/step - loss: 2.1482 - accuracy: 0.2987 - val_loss: 2.0672 - val_accuracy: 0.3763\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.9321 - accuracy: 0.3227 - val_loss: 1.6841 - val_accuracy: 0.3763\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.5915 - accuracy: 0.3253 - val_loss: 1.5424 - val_accuracy: 0.4624\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.4613 - accuracy: 0.4187 - val_loss: 1.3156 - val_accuracy: 0.4624\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.2382 - accuracy: 0.4667 - val_loss: 1.0845 - val_accuracy: 0.4086\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9416 - accuracy: 0.5600 - val_loss: 0.7576 - val_accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5877 - accuracy: 0.8320 - val_loss: 0.4454 - val_accuracy: 0.8710\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.3368 - accuracy: 0.9387 - val_loss: 0.3245 - val_accuracy: 0.8710\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2448 - accuracy: 0.9013 - val_loss: 0.2659 - val_accuracy: 0.9677\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2107 - accuracy: 0.9520 - val_loss: 0.2683 - val_accuracy: 0.8710\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 8s 155ms/step - loss: 2.1589 - accuracy: 0.2827 - val_loss: 2.0693 - val_accuracy: 0.4194\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 1.9765 - accuracy: 0.3120 - val_loss: 1.6963 - val_accuracy: 0.4194\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 1.6549 - accuracy: 0.3120 - val_loss: 1.4648 - val_accuracy: 0.4194\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 1.4871 - accuracy: 0.3120 - val_loss: 1.3546 - val_accuracy: 0.4194\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 1.3258 - accuracy: 0.3973 - val_loss: 1.0902 - val_accuracy: 0.6237\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0030 - accuracy: 0.6533 - val_loss: 0.7690 - val_accuracy: 0.8280\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6556 - accuracy: 0.8293 - val_loss: 0.4826 - val_accuracy: 0.8925\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.3824 - accuracy: 0.9467 - val_loss: 0.2431 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.2565 - accuracy: 0.9493 - val_loss: 0.1912 - val_accuracy: 0.9570\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.2134 - accuracy: 0.9413 - val_loss: 0.1702 - val_accuracy: 0.9570\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming 'data' is your DataFrame and already preprocessed\n",
    "max_length = max(data['path_encoded'].apply(len))\n",
    "X = pad_sequences(data['path_encoded'], maxlen=max_length, padding='post')\n",
    "y = data['destination_encoded'].values\n",
    "\n",
    "# Define the K-Fold Cross Validator\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-Fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=len(index_to_label), output_dim=50, input_length=max_length),\n",
    "        LSTM(100),\n",
    "        Dense(len(index_to_label), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=32, validation_data=(X[test], y[test]))\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbb3763-af1e-42c7-8ff7-b7462c28b795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the source node:  B\n",
      "Enter the destination node:  H\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted Path: I > H\n",
      "Number of Hops: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('path_prediction_model.h5')\n",
    "\n",
    "# Assuming `index_to_label` and `label_encoder` are predefined as in your preprocessing script\n",
    "index_to_label = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I'}\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(list(index_to_label.values()))\n",
    "\n",
    "# Function to predict path\n",
    "def predict_path(source, destination):\n",
    "    if source not in index_to_label.values() or destination not in index_to_label.values():\n",
    "        return \"Invalid Source or Destination\"\n",
    "    \n",
    "    source_encoded = label_encoder.transform([source])[0]\n",
    "    destination_encoded = label_encoder.transform([destination])[0]\n",
    "    \n",
    "    # Create a dummy input for LSTM with the correct shape\n",
    "    max_length = 6  # Adjust this to match your model's expected input length\n",
    "    dummy_input = np.array([[source_encoded] + [0] * (max_length - 1)])  # Ensure the input length matches the expected shape\n",
    "\n",
    "    # Predict the path\n",
    "    predicted_path_encoded = model.predict(dummy_input)\n",
    "    predicted_path_encoded = np.argmax(predicted_path_encoded, axis=1)\n",
    "    predicted_path = [index_to_label[idx] for idx in predicted_path_encoded]\n",
    "\n",
    "    # Remove padding and create actual path\n",
    "    actual_path = []\n",
    "    for node in predicted_path:\n",
    "        if node == destination:\n",
    "            actual_path.append(node)\n",
    "            break\n",
    "        actual_path.append(node)\n",
    "    if destination not in actual_path:\n",
    "        actual_path.append(destination)\n",
    "    \n",
    "    number_of_hops = len(actual_path) - 1\n",
    "    return actual_path, number_of_hops\n",
    "\n",
    "# Main code to take input and provide the output\n",
    "if __name__ == \"__main__\":\n",
    "    source = input(\"Enter the source node: \").strip()\n",
    "    destination = input(\"Enter the destination node: \").strip()\n",
    "    \n",
    "    path, hops = predict_path(source, destination)\n",
    "    \n",
    "    if isinstance(path, str):  # Error message case\n",
    "        print(path)\n",
    "    else:\n",
    "        print(f\"Predicted Path: {' > '.join(path)}\")\n",
    "        print(f\"Number of Hops: {hops}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
