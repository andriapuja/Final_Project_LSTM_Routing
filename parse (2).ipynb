{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7beec67-de62-4407-88e1-18d5dc7cb4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Output written to dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "def parse_line(line):\n",
    "    \"\"\" Extracts details from each log line. \"\"\"\n",
    "    parts = line.split()\n",
    "    timestamp = float(parts[1])\n",
    "    node_info = parts[2]\n",
    "    node_id = node_info.split('/')[2].replace('NodeList', '')\n",
    "    action = parts[0]\n",
    "    ip_header_info = ' '.join(parts[8:])\n",
    "    source_ip = ip_header_info.split('>')[0].split()[-1]\n",
    "    destination_ip = ip_header_info.split('>')[1].split()[0].rstrip(')')\n",
    "    packet_id = ip_header_info.split('id')[1].split()[0]  # Capture packet ID\n",
    "    return source_ip, destination_ip, node_id, timestamp, packet_id\n",
    "\n",
    "def track_flows(log_file):\n",
    "    \"\"\" Tracks each flow with unique identifiers and accumulates nodes visited. \"\"\"\n",
    "    flows = defaultdict(lambda: {'nodes': OrderedDict(), 'first_timestamp': float('inf')})\n",
    "    with open(log_file, 'r') as file:\n",
    "        for line in file:\n",
    "            source, destination, node_id, timestamp, packet_id = parse_line(line)\n",
    "            flow_id = (source, destination, packet_id)  # Distinguish flows also by packet ID\n",
    "            if node_id not in flows[flow_id]['nodes']:\n",
    "                flows[flow_id]['nodes'][node_id] = True  # Mark the node as visited\n",
    "            if timestamp < flows[flow_id]['first_timestamp']:\n",
    "                flows[flow_id]['first_timestamp'] = timestamp  # Update the minimum timestamp for the flow\n",
    "\n",
    "    return flows\n",
    "\n",
    "def write_flows_to_csv(flows, output_file):\n",
    "    \"\"\" Writes the tracked flows to a CSV file, including the first timestamp. \"\"\"\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['timestamp', 'source', 'destination', 'packet id', 'path', 'number of hops']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for (source, destination, packet_id), data in flows.items():\n",
    "            path = ' > '.join(data['nodes'].keys())\n",
    "            num_hops = len(data['nodes']) - 1\n",
    "            writer.writerow({\n",
    "                'timestamp': data['first_timestamp'],\n",
    "                'source': source,\n",
    "                'destination': destination,\n",
    "                'packet id': packet_id,\n",
    "                'path': path,\n",
    "                'number of hops': num_hops\n",
    "            })\n",
    "\n",
    "def process_tr_file(input_file, output_file):\n",
    "    flows = track_flows(input_file)\n",
    "    write_flows_to_csv(flows, output_file)\n",
    "    print(\"Processing complete. Output written to\", output_file)\n",
    "\n",
    "# Call the function with file names\n",
    "process_tr_file('dataset.tr', 'dataset.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
